[toc]
隐马尔科夫模型（hidden Markov model，HMM）是可用于**标注**问题的统计学习模型，描述由隐藏的马尔可夫链随机生成观测序列的过程，属于生成模型。隐马尔可夫模型在语音识别、自然语言处理、生物信息、模式识别等领域有着广泛的应用。

> 本文内容部分引用于 李航《统计学习方法》
## 1. 基本概念

### 1.1 HMM模型定义
- 隐马尔可夫模型是关于时序的概率模型，描述由一个**隐藏**的马尔可夫链随机生成**不可观测**的状态随机序列，再由各个状态**生成**一个观测从而产生**观测随机序列**的过程。
- 隐藏的马尔可夫链随机生成的状态的序列，称为状态序列（state sequence）；
- 每个状态生成一个观测，而由此产生的观测的随机序列，称为观测序列（observation sequence）。
- 序列的每一个位置又可以看作是一个时刻。

> 一个不一定恰当的例子：你只知道一个人今天是散步了，逛街了，还是在家打扫卫生，推测今天的天气；这个人在下雨天可能在家打扫卫生，也有可能雨中散步，晴天可能去逛街，也有可能散步，或者打扫卫生
> 隐藏状态 Y（不可见）：下雨，晴天 
> 观察状态 X（可见）： 散步，逛街，打扫房间

假设我们观测到的状态是$X$序列，$X=(x_1,x_2,x_3,...x_n)$,  隐藏状态是$Y$序列，$Y=(y_1,y_2,y_3,...y_n)$

我们在知道观测序列$X$的情况下，求有多大概率是该隐藏状态序列$Y$

- 贝叶斯公式  $P(B|A)=\frac {P(AB)}{P(A)}=\frac{P(A|B)P(B)}{P(A)}$

现在我们要求的就是$P(Y|X)$
$$
\begin{aligned}
P(Y|X)
& = P(y_1,y_2,y_3,\cdots,y_n|x_1,x_2,x_3,\cdots,x_n)\\
& =\frac{P(x_1,x_2,x_3,\cdots,x_n|y_1,y_2,y_3,\cdots,y_n)P(y_1,y_2,y_3,\cdots,y_n)}{P(x_1,x_2,x_3,\cdots,x_n)}\quad\quad(0)\\
P(y_1,y_2,y_3,\cdots,y_n)
& =P(y_1){\color{red}P(y_2,y_3,y_4,\cdots,y_n|y_1)}\\
& =P(y_1)P(y_2|y_1){\color{red}P(y_3,y_4,\cdots,y_n|y_1,y_2)}\\
& =P(y_1)P(y_2|y_1)P(y_3|y_1,y_2){\color{red}P(y_4,\cdots,y_n|y_1,y_2,y_3)}\\
\vdots\\
& =P(y_1)P(y_2|y_1)P(y_3|y_1,y_2)\cdots P(y_{n-1}|y_1,y_2,\cdots,y_{n-2})P(y_n|y_1,y_2,\cdots,y_{n-1})\\
& =P(y_1)\prod_{i=2}^{n}P(y_i|y_1,y_2,y_3,\cdots,y_{i-1})\\
& =\color{blue}{P(y_1)\prod_{i=2}^{n}P(y_i|y_{i-1})}\quad\quad\quad(1)\\
\end{aligned}
$$

隐马尔可夫模型<font color=#FF0000>  **两个假设** </font>
- 上式最后一步是隐马尔可夫的 **齐次性** 假设：当前状态 $y_i$ **仅依赖**于前一个状态 $y_{i-1}$ 
- 下面式子最后一步是隐马尔可夫的 **观测独立性** 假设：观测值 $x_i$ 只跟他的隐含状态 $y_i$ 相关


$$
\begin{aligned}
&P(x_1,x_2,x_3,\cdots,x_n|y_1,y_2,y_3,\cdots,y_n)\\
=&\prod_{i=1}^{n}P(x_i|x_1,x_2,x_3,\cdots,x_{i-1},y_1,y_2,y_3,\cdots,y_n)\\
=&\color{blue}\prod_{i=1}^{n}P(x_i|y_i)\quad\quad\quad(2)\\
\end{aligned}
$$

- 由$(1)(2)$, 且$(0)$式忽略分母
$$
\begin{aligned}
P(Y|X) 
=&P(y_1,y_2,y_3,\cdots,y_n|x_1,x_2,x_3,\cdots,x_n)\\
=&\frac{P(x_1,x_2,x_3,\cdots,x_n|y_1,y_2,y_3,\cdots,y_n)P(y_1,y_2,y_3,\cdots,y_n)}{P(x_1,x_2,x_3,\cdots,x_n)}\\
\approx & \color{blue}{P(y_1)\prod_{i=2}^{n}P(y_i|y_{i-1})}\prod_{i=1}^{n}P(x_i|y_i) = P(XY)
\end{aligned}
$$

隐马尔可夫模型由<font color=#FF0000>  **三要素** </font>决定
- **初始状态概率向量** $\pi$,（初始处于各个隐藏状态 $y_i$ 的概率）
- **状态转移概率矩阵** $A$,（即式（1）中的 $P(y_i|y_{i-1})$ 的各种项构成的矩阵）
- **观测概率矩阵** $B$, （即式（2）中的 $P(x_i|y_i)$ 的各种项构成的矩阵）

$\pi$ 和 $A$ 决定状态序列，$B$ 决定观测序列。隐马尔可夫模型 $\lambda$ 可以用三元符号表示，$\lambda=（A，B，\pi）$

- **状态转移概率矩阵** $A$ 与 **初始状态概率向量** $\pi$ 确定了**隐藏的马尔可夫链**，生成不可观测的状态序列。
- **观测概率矩阵** $B$ 确定了如何从隐藏状态 $y_i$ 生成观测 $x_i$，与状态序列综合确定了如何产生观测序列。

### 1.2 盒子和球模型
假设有4个盒子，每个盒子里都装有红、白两种颜色的球，盒子里的红、白球数由表列出。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20191207140716909.png)
按下面的方法抽球，产生一个球的颜色的**观测**序列 $X$：
- **等概率**随机选1个盒子，从这个盒子里随机抽出1个球，记录颜色，放回；
- 从当前盒子随机转移到下一个盒子，规则是：如果当前盒子是盒子1，那么下一盒子一定是盒子2；如果当前是盒子2或3，那么分别以概率0.4和0.6转移到左边或右边的盒子；如果当前是盒子4，那么各以0.5的概率停留在盒子4或转移到盒子3；
- 确定转移的盒子后，再从这个盒子里随机抽出1个球，记录颜色，放回；
- 重复5次，得到一个球的颜色的观测序列
![在这里插入图片描述](https://img-blog.csdnimg.cn/20191207143232811.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9taWNoYWVsLmJsb2cuY3Nkbi5uZXQ=,size_16,color_FFFFFF,t_70)
- 各个隐含状态的初始概率 $P(y_i)$ ： $\pi = (0.25,0.25,0.25,0.25)^T$
- 各个隐含状态间的转移概率 $P(y_i|y_{i-1})$ ： $A = 
\begin{bmatrix}
0 & 1 & 0 & 0 \\
0.4 & 0 & 0.6 & 0 \\
0 & 0.4 & 0 & 0.6 \\
0 & 0 & 0.5 & 0.5 \\
\end{bmatrix}$
- 观测概率 $P(x_i|y_i)$：$B = \begin{bmatrix}
0.5 & 0.5  \\
0.3 & 0.7  \\
0.6 & 0.4  \\
0.8 & 0.2   \\
\end{bmatrix}$

### 1.3 观测序列生成过程


- 输入：隐马模型 $\lambda=（A，B，\pi）$，观测序列长度 $T$ (该例子为 5)
- 输出：观测序列 $X = (x_1,x_2,x_3,x_4,x_5)$ , (红、白球)

1. 跟据 $\pi$ 随机产生一个 $y_i$ 状态(盒子), 序列长度 t = 0
2. 在 $y_i$ 中，按照其观测概率 $B$ 对应的行，产生一个观测序列 $X$ 的元素 $x_i$（红球 or 白球），计数 t++
3. 根据 $y_i$ 的状态转移概率 $A$ 对应的行，产生下一个状态 $y_{i+1}$ , `while(t < T), 重复2,3步骤`

### 1.4 HMM模型3个基本问题
1. 概率计算问题：给定模型 $\lambda=（A，B，\pi）$ 和 观测序列 $X = (x_1,x_2.....,x_n)$, 计算在模型 $\lambda$ 下，观测序列 $X$ 出现的概率 $P(X|\lambda)$
2. 学习问题：已知观测序列  $X = (x_1,x_2.....,x_n)$，估计模型 $\lambda=（A，B，\pi）$ 的参数，使得在该模型下，观测序列概率 $P(X|\lambda)$ 最大。极大似然估计的方法估计参数
3. 预测问题：也称解码(decoding)问题。已知模型 $\lambda=（A，B，\pi）$ 和 观测序列 $X = (x_1,x_2.....,x_n)$，求对给定观测序列条件概率 $P(Y|X)$ 最大的状态序列 $Y = (y_1,y_2......,y_n)$。即给定观测序列 $X$，求最有可能的对应隐含状态序列 $Y$

## 2. 概率计算问题

给定模型 $\lambda=（A，B，\pi）$ 和 观测序列 $X = (x_1,x_2.....,x_n)$, 计算在模型 $\lambda$ 下，观测序列 $X$ 出现的概率 $P(X|\lambda)$
### 2.1 直接计算法
- 列举所有的长度为 $T$ 的状态序列 $Y = (y_1,y_2......,y_t)$
- 求 各个 状态序列 $Y$ 与 观测序列 $X = (x_1,x_2.....,x_t)$ 的联合概率 $P(XY|\lambda)$
- 然后对上面所有的状态序列求和 $\Sigma$，得到 $P(X|\lambda)$

状态